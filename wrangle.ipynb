{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a710ae-fdba-493f-9577-435bc717f4bd",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738ba2d7-3f94-4d13-9d88-e43b180246a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from env import get_db_url\n",
    "import os\n",
    "\n",
    "def get_log_data():\n",
    "\n",
    "    '''\n",
    "    This function acquires curriculum log data by accessing a SQL database and performing a SQL query to acquire\n",
    "    selected curriculum log tables and columns and return it to a dataframe. Additionally, data is stored in a .csv \n",
    "    making it more efficient for future utilization of the same function.\n",
    "    '''\n",
    "\n",
    "    filename = 'curriculum_logs.csv'\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    else:\n",
    "        sql = \"\"\"\n",
    "        SELECT *\n",
    "        FROM logs\n",
    "        LEFT JOIN cohorts ON logs.cohort_id = cohorts.id\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_sql(sql, get_db_url('curriculum_logs'))\n",
    "\n",
    "        df.to_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7e269-a203-4fbe-b3f5-427f82b6d595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709ee51-bd0f-4df3-b338-b074c5ff532b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313283c7-ad63-4ba8-b4f9-d9f4bb927b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53036f7e-0dee-41eb-be2c-2fe25c8406bb",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cb5d15-d9e0-4ecd-8c02-c0b24c087f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "\n",
    "def prepare_logs(use_cache=True):\n",
    "    \"\"\"This function takes in the DataFrame from the get_log_data function located in the acquire file.\n",
    "    Args: none. \n",
    "    Columns dropped: 'slack', 'id', and 'deleted_at'.\n",
    "    Columns renamed: mapped values for program type to integers in 'program_id' column.\n",
    "    Columns converted: 'start_date', 'end_date', 'created_at', 'updated_at' converted to DTG format.\n",
    "    Columns concat: 'date' and 'time', converted to DTG\n",
    "    Returns: prepared DF, and CSV named 'codeup_logs.csv'\n",
    "      \"\"\"\n",
    "      #use local cache from CSV if available\n",
    "    filename = \"codeup_logs.csv\"\n",
    "    if os.path.isfile(filename) and use_cache:\n",
    "        return pd.read_csv(filename)\n",
    "    # acquire the data\n",
    "    df = df = acquire.get_log_data()\n",
    "    # drop unnecessary columns\n",
    "    df = df.drop(columns=(['slack', 'id', 'deleted_at', 'Unnamed: 0']))\n",
    "    # map programs to program ids\n",
    "    df.program_id = df.program_id.map({1.0:'full_stack_php', \n",
    "    2.0:'full_stack_java', 3.0:'data_science', 4.0:'front_end_programming'})\n",
    "    # convert dates to DTG\n",
    "    dates = ['start_date', 'end_date', 'created_at', 'updated_at']\n",
    "    for col in dates:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    # change cohort names to lower case\n",
    "    df.name = df.name.str.lower()\n",
    "    # convert date-time to DTG\n",
    "    df['date_time'] = df.date + \" \" + df.time\n",
    "    df.date_time = pd.to_datetime(df.date_time)\n",
    "    # drop unnecessary columns\n",
    "    df = df.drop(columns=(['date', 'time']))\n",
    "    # add 'to_csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_q2_eda(df):\n",
    "    '''\n",
    "    Creates a new dataframe for question 2,\n",
    "    \"Is there a cohort that referred to a lesson significantly more than other cohorts seemed to gloss over?\"\n",
    "    by dropping rows that aren't cohorts and renaming columns.\n",
    "    '''\n",
    "        \n",
    "    # Removes all rows with null values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Drops rows that are staff under the 'name' column \n",
    "    df = df[(df['name'] != 'staff')] \n",
    "\n",
    "    # Renames specified columns\n",
    "    df2 = df.copy()\n",
    "    df2 = df2.rename(columns={'name': 'cohorts', 'program_id': 'programs'})\n",
    "    return df2\n",
    "\n",
    "\n",
    "def get_q6_eda_df():\n",
    "    '''This function converts the column types in the CSV from object to the correct type. Using the CSV cached locally results in dates saved as 'object; instead of datetimes'''\n",
    "    \n",
    "    df = prepare_logs()\n",
    "    df.date_time = pd.to_datetime(df.date_time)\n",
    "      # convert dates to DTG\n",
    "    dates = ['start_date', 'end_date', 'created_at', 'updated_at']\n",
    "    for col in dates:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "        # drop unnecessary columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672d323-6bae-4b36-8e80-c90bf67833dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
